# LSTM - Stock Prediction üìà

O objetivo deste projeto √© desenvolver um modelo preditivo utilizando redes neurais LSTM (Long Short Term Memory) para prever o valor de fechamento de a√ß√µes.

O projeto abrange desde a ingest√£o de dados, pr√©-processamento de s√©ries temporais, treinamento de modelo e disponibiliza√ß√£o via API containerizada com monitoramento em tempo real.

## üèóÔ∏è Arquitetura da Solu√ß√£o

O fluxo de dados foi projetado para ser modular e reprodut√≠vel, utilizando o padr√£o de microservi√ßos:

1. Ingest√£o (scripts/): Script Python que consome dados hist√≥ricos via yfinance e armazena em CSV.
2. Treinamento (notebooks/): Pipeline de Ci√™ncia de Dados incluindo limpeza, normaliza√ß√£o com MinMaxScaler, estrutura√ß√£o de janelas temporais de 60 dias e treinamento da rede LSTM.
3. Artefatos (app/saved_models/): Exporta√ß√£o do modelo treinado (.keras) e do escalonador (.pkl).
4. Servi√ßo (app/): API FastAPI que carrega os artefatos e exp√µe endpoints de predi√ß√£o e m√©tricas.
5. Observabilidade: Stack composta por Prometheus para coleta de m√©tricas e Grafana para visualiza√ß√£o de performance.
6. Orquestra√ß√£o (Docker): Containeriza√ß√£o completa para garantir a paridade de ambiente, otimizada para arquitetura Apple Silicon (M4).

---

## üìÇ Estrutura do Projeto

* app/
  * main.py (Servidor FastAPI com l√≥gica de infer√™ncia e instrumenta√ß√£o de m√©tricas)
  * Dockerfile (Receita do container Python 3.13-slim)
  * requirements.txt (Depend√™ncias da API e Prometheus)
  * saved_models/ (Artefatos do modelo)
* data/ (Base de dados hist√≥rica em CSV)
* monitoring/
  * prometheus.yml (Configura√ß√£o de coleta de dados do Prometheus)
* notebooks/
  * training.ipynb (Desenvolvimento do modelo e valida√ß√£o)
* scripts/
  * ingest_data.py (Coleta de dados)
  * generate_test_json.py (Utilit√°rio para massa de dados de teste)
* docker-compose.yml (Orquestrador multi-container: API, Prometheus e Grafana)

---

## üöÄ Como Rodar o Projeto

### Pr√©-requisitos
* Docker e Docker Compose instalados.

### 1. Subir a Stack Completa
Na raiz do projeto, execute o comando abaixo para construir as imagens e subir os servi√ßos:

docker compose up --build

A stack estar√° dispon√≠vel nos seguintes endere√ßos:
* API FastAPI: http://localhost:8000
* Prometheus: http://localhost:9090
* Grafana: http://localhost:3000 (Login padr√£o: admin/admin)

### 2. Gerar Dados de Teste
Para testar a API com os dados reais mais recentes, utilize o script auxiliar:

python scripts/generate_test_json.py

---

## üß™ Testando a Predi√ß√£o

### Interface Swagger (Visual)
Acesse http://localhost:8000/docs, utilize o endpoint POST /predict e cole o conte√∫do do arquivo app/test_input.json.

### Via Terminal (cURL)
curl -X 'POST' 'http://localhost:8000/predict' -H 'Content-Type: application/json' -d @app/test_input.json

---

## üìä Monitoramento e Escalabilidade

O projeto atende aos requisitos de monitoramento e escalabilidade atrav√©s de:
* Rastreio de Performance: Coleta autom√°tica de lat√™ncia de resposta e contagem de requisi√ß√µes por segundo via Prometheus.
* Visualiza√ß√£o: Dashboard no Grafana para acompanhamento da sa√∫de da aplica√ß√£o em tempo real.
* Escalabilidade: Deploy containerizado facilitando o escalonamento horizontal e o uso de orquestradores como Kubernetes.
* Recursos: Monitoramento de utiliza√ß√£o de CPU e Mem√≥ria via comando 'docker stats'.

---

## ‚öôÔ∏è Detalhes T√©cnicos do Modelo

* Algoritmo: LSTM (Long Short Term Memory) com camadas de Dropout (0.2).
* Input: Janelas deslizantes de 60 dias (Window Size).
* Performance: O modelo atingiu um MAE (Erro M√©dio Absoluto) de aproximadamente 3.13.

---